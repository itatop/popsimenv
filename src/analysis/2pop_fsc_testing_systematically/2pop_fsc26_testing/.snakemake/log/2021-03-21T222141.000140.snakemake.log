Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	6	get_best_fsc_runs
	6	plot_estimates
	13
Select jobs to execute...

[Sun Mar 21 22:21:45 2021]
rule get_best_fsc_runs:
    input: experiment/1845187043_reg/Intermediate/fsc_analysis/fsc_results_sorted.txt, experiment/1675701734_reg/Intermediate/fsc_analysis/fsc_results_sorted.txt, experiment/1845187043_hi/Intermediate/fsc_analysis/fsc_results_sorted.txt, experiment/1675701734_hi/Intermediate/fsc_analysis/fsc_results_sorted.txt, experiment/1845187043_lo/Intermediate/fsc_analysis/fsc_results_sorted.txt, experiment/1675701734_lo/Intermediate/fsc_analysis/fsc_results_sorted.txt
    output: experiment1845187043_reg/Results/best_fsc_runs.txt
    jobid: 2
    wildcards: seeds=1845187043, model_mode=reg

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /code/src/analysis/2pop_fsc26_testing/.snakemake/log/2021-03-21T222141.000140.snakemake.log
