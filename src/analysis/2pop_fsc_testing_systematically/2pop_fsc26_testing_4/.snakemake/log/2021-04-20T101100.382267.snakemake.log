Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	2	plot_estimates
	3
Select jobs to execute...

[Tue Apr 20 10:11:03 2021]
rule plot_estimates:
    input: experiment/reg/1845187043/Results/best_fsc_run.txt
    output: experiment/reg/1845187043/Results/estimates_N_tdiv_fsc.png, experiment/reg/1845187043/Results/estimates_mig_fsc.png
    jobid: 1
    wildcards: model_mode=reg, seeds=1845187043

[Tue Apr 20 10:11:07 2021]
Finished job 1.
1 of 3 steps (33%) done
Select jobs to execute...

[Tue Apr 20 10:11:07 2021]
rule plot_estimates:
    input: experiment/high/1845187043/Results/best_fsc_run.txt
    output: experiment/high/1845187043/Results/estimates_N_tdiv_fsc.png, experiment/high/1845187043/Results/estimates_mig_fsc.png
    jobid: 10
    wildcards: model_mode=high, seeds=1845187043

[Tue Apr 20 10:11:12 2021]
Finished job 10.
2 of 3 steps (67%) done
Complete log: /code/src/analysis/2pop_fsc_testing_systematically/2pop_fsc26_testing_4/.snakemake/log/2021-04-20T101100.382267.snakemake.log
